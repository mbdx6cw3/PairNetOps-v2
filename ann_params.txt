# input parameters for loading, training or testing a neural network
# activation functions (e.g. "silu")
activations  = silu

# number of epochs
epochs       = 1000

# number of layers
n_layers     = 3

# number of nodes
n_nodes      = 360, 360, 360

# size of train, validation and test sets
n_data       = 1000, 100, 100

# define custom loss function weights (forces, energy, charges)
loss_weights = 0.95, 0.05, 0.00

# charge scheme (0-5)
charge_scheme = 1

# normalisation scheme ("z-score", "force" or "none")
norm_scheme = z-score

# batch size
batch_size = 32

# set learning rate parameters
init_lr      = 5e-4
min_lr       = 1e-7
lr_patience  = 2000
lr_factor    = 0.5

